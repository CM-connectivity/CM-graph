{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9376c5da-f0c6-4eaa-9ac4-764a5f45691b",
   "metadata": {},
   "source": [
    "# Neural plasticity is related to the behavior\n",
    "## Chapter 1: check motor related potential (alpha band)\n",
    "- preprocessing\n",
    "    - create epoch for 20s/2s IMC, including EEG and EMG\n",
    "    - identify bad chs\n",
    "    - notch filter and bandpass\n",
    "    - prepare epoch data, calculate muscle synergy for each subject (using var to decide the number), track explained variance\n",
    "    - knn to cluster synergies and label them as 'ch_name'\n",
    "    - create 2s epochs\n",
    "- oscillatory analysis\n",
    "- coherence analysis\n",
    "    - alpha 4 FBC\n",
    "    - CMC: alpha-activation\n",
    "    - IMC: cosine similarity\n",
    "## Notation:\n",
    "- P1i: ipsilesional P1\n",
    "- 34,35 are processed, redo prep on others \n",
    "## Calculate muscle synergy, and KNN identified common synergy\n",
    "## whole brain cmc analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7a6240-9182-4dc9-b79c-ec33b6d190fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Import #####################\n",
    "import os,mne,numpy as np, pandas as pd\n",
    "from mne.preprocessing import ICA\n",
    "from mne.time_frequency import tfr_morlet\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch\n",
    "from fooof import FOOOF\n",
    "from fooof import FOOOFGroup\n",
    "from fooof.objs import fit_fooof_3d, combine_fooofs\n",
    "from mne.viz import plot_topomap\n",
    "from mne.time_frequency import psd_welch\n",
    "from matplotlib import cm, colors, colorbar\n",
    "\n",
    "from fooof.bands import Bands\n",
    "from fooof.analysis import get_band_peak_fg\n",
    "from fooof.plts.spectra import plot_spectrum\n",
    "%matplotlib qt\n",
    "#############################################\n",
    "########### function def\n",
    "def emg2synergy(emg_data, emg_ch_names, show=True, n_components=3):\n",
    "    '''\n",
    "    parameters\n",
    "    ----------\n",
    "    emg_data: 2D numpy array (chs, time)\n",
    "    emg_ch_names: list of str\n",
    "    show: whether to visualize muscle synergy\n",
    "    n_components: None or int. It should be greater than 2. Default 3. If specified, NMF will yield 3 muscle synergies. \n",
    "    If None, n_components = number of chs - 2 \n",
    "    Notes\n",
    "    -----\n",
    "    We do not specify VAF_threhold and VAF_diff_threshold\n",
    "    '''\n",
    "    # build aligned_synergy_raw with muscle activation and synergic module factorization\n",
    "    emg_data4muscleActivation = emg_data.copy()\n",
    "    # bandpass to correct artifacts\n",
    "    emg_data4muscleActivation = mne.filter.filter_data(emg_data4muscleActivation, sfreq=1000, l_freq=20, h_freq=400, method='iir')\n",
    "    # demean\n",
    "    emg_data4muscleActivation -= emg_data4muscleActivation.mean(axis=1)[:, None]\n",
    "    emg_data4muscleActivation = np.abs(emg_data4muscleActivation)  # rectification\n",
    "    emg_data4muscleActivation = emg_data4muscleActivation / np.max(emg_data4muscleActivation)  # normalization\n",
    "    # emg_data2test /= emg_data2test.max(axis=1)[:, None] #  find max for each ch\n",
    "\n",
    "    emg_data4muscleActivation = mne.filter.filter_data(emg_data4muscleActivation,\n",
    "                                                       sfreq=1000, l_freq=None, h_freq=45, method='iir')  # low-pass smoothing,\n",
    "    # please note that negative values appear in this step\n",
    "    # muscle excitation (recursive filter)\n",
    "    d = 10  # 10ms\n",
    "    c1 = 0.5\n",
    "    c2 = 0.5\n",
    "    beta1 = c1 + c2\n",
    "    beta2 = c1 * c2\n",
    "    alpha = 1 + beta1 + beta2\n",
    "    muscle_excitation = np.zeros(emg_data4muscleActivation.shape)\n",
    "    for i in range(emg_data4muscleActivation.shape[1]-d):\n",
    "        muscle_excitation[:, i+d] = alpha * emg_data4muscleActivation[:, i] - beta1*muscle_excitation[:, i+d-1] -\\\n",
    "        beta2 * muscle_excitation[:, i + d - 2]\n",
    "    # muscle activation\n",
    "    A = -1.5\n",
    "    muscle_activation = (np.exp(A * muscle_excitation) - 1) / (np.exp(A) -1)\n",
    "    if np.min(muscle_activation) < 0:  # handle negative values\n",
    "        muscle_activation -= np.min(muscle_activation)\n",
    "\n",
    "    # non-negative matrix factorization iterate from 2\n",
    "    # stopping condition: as the n_components increase, the reconstruction error (Frobenius norm of the matrix difference) does not reduce significantly\n",
    "    # In practice, the n_compoents stop increasing when VAF(n + 1) - VAF(n) < 0.05 or VAF(n) > 0.85\n",
    "    VAF_diff = 1\n",
    "    VAF_n = 0\n",
    "    assert len(emg_ch_names) > 2, \"must have more than 2 emg chs\"\n",
    "    if n_components is None:\n",
    "        n_components = len(emg_ch_names) - 2\n",
    "    n_components_init = 2\n",
    "    VAF = []\n",
    "    VAF_diff = []\n",
    "    n_componentsInLoop = n_components_init\n",
    "    while (n_componentsInLoop < (len(emg_ch_names) - 1)):\n",
    "        model_n = NMF(n_components=n_componentsInLoop, init='random', random_state=0, max_iter=10000)  # max iteration is set to 10000\n",
    "        model_n.fit_transform(muscle_activation)\n",
    "        if n_componentsInLoop == n_components:\n",
    "            muscle_synergy = model_n.fit_transform(muscle_activation)\n",
    "            synergy_factor = model_n.components_   # the activation time course\n",
    "        VAF_n = 1 - model_n.reconstruction_err_ / np.linalg.norm(muscle_activation)  # frobenius norm\n",
    "        model_nPlus1 = NMF(n_components=n_componentsInLoop+1, init='random', random_state=0, max_iter=10000)\n",
    "        model_nPlus1.fit_transform(muscle_activation)\n",
    "        VAF_nPlus1 = 1 - model_nPlus1.reconstruction_err_ / np.linalg.norm(muscle_activation)\n",
    "        VAF_diff_n = np.abs(VAF_n - VAF_nPlus1)\n",
    "        VAF.append(VAF_n)\n",
    "        VAF_diff.append(VAF_diff_n)\n",
    "        n_componentsInLoop += 1\n",
    "    df_muscle_synergy = pd.DataFrame(muscle_synergy.T, columns=emg_ch_names)\n",
    "    if show:\n",
    "        fig, axes = plt.subplots((n_components-1) // 4 + 1, 4, figsize=(24, 18))  # four cols\n",
    "        if n_components > 4:\n",
    "            for num_synergy in range(n_components):\n",
    "                sns.barplot(ax=axes[num_synergy // 4, num_synergy % 4], x=df_muscle_synergy.columns, y=df_muscle_synergy.iloc[num_synergy].values,\n",
    "                            color=sns.color_palette(n_colors=synergy_factor.shape[0])[num_synergy],\n",
    "                            label='synergy_' + str(num_synergy))\n",
    "                axes[num_synergy // 4, num_synergy % 4].set_title('synergic module' + str(num_synergy))\n",
    "        else:\n",
    "            for num_synergy in range(df_muscle_synergy.shape[0]):\n",
    "                sns.barplot(ax=axes[num_synergy % 4], x=df_muscle_synergy.columns, y=df_muscle_synergy.iloc[num_synergy].values,\n",
    "                            color=sns.color_palette(n_colors=synergy_factor.shape[0])[num_synergy],\n",
    "                            label='synergy_' + str(num_synergy))\n",
    "                axes[num_synergy % 4].set_title('synergic module' + str(num_synergy))\n",
    "        plt.show()\n",
    "    return muscle_synergy, synergy_factor, VAF, VAF_diff\n",
    "\n",
    "def firstOnsetD(possibleOnsets):\n",
    "    n=len(possibleOnsets)\n",
    "    st_idx = 0\n",
    "    onsets = []\n",
    "    while st_idx < n-1:\n",
    "        end = st_idx + 1\n",
    "        dif = possibleOnsets[end] - possibleOnsets[st_idx]\n",
    "        while end < n - 1 and possibleOnsets[end + 1] - possibleOnsets[end] == dif:\n",
    "            end += 1\n",
    "        onsets.append(possibleOnsets[st_idx])\n",
    "        st_idx = end+1\n",
    "    return onsets\n",
    "\n",
    "def findOnsets(numberOfEpochs,raw_emg2cut,signature_chs_list,step=200,windowLen=3000,energy_q=0.99,energy_q_step=0.04,sfreq_emg=1000,onset_tuning=0):\n",
    "    onsets = []\n",
    "    try:\n",
    "        while len(onsets) != numberOfEpochs:\n",
    "            # pulling segmentation  - find best segmentation EMG-ch candidate\n",
    "            signature_chsPower = [raw_emg2cut.to_data_frame()[ch].abs().sum() for ch in signature_chs_list]\n",
    "            signature_ch = signature_chs_list[signature_chsPower.index(max(signature_chsPower))]\n",
    "            df = raw_emg2cut.to_data_frame()[signature_ch].abs()\n",
    "            emgEnergy = df.rolling(windowLen, win_type='boxcar').sum().dropna()[::step]\n",
    "            possibleOnsets =np.array(emgEnergy[emgEnergy>emgEnergy.quantile(energy_q)].index.tolist())-windowLen\n",
    "            onsets =np.array(firstOnsetD(possibleOnsets)) / sfreq_emg + onset_tuning  #related rto sampling rate of EMG, it is the time in seconds\n",
    "            energy_q-=energy_q_step\n",
    "    except:\n",
    "        return False,onsets\n",
    "#     print(len(onsets))\n",
    "    return True,onsets\n",
    "#############################\n",
    "\n",
    "chs_map_rParetic = {'Fp1':'Fp1i','AF3':'AF3i','F3':'F3i','F7':'F7i','FC1':'FC1i','FC5':'FC5i','C3':'C3i',\n",
    "                        'T7':'T7i','CP1':'CP1i','CP5':'CP5i','P3':'P3i','P7':'P7i','PO3':'PO3i','O1':'O1i',\n",
    "                       'Fp2':'Fp1c','AF4':'AF3c','F4':'F3c','F8':'F7c','FC2':'FC1c','FC6':'FC5c','C4':'C3c',\n",
    "                       'T8':'T7c','CP2':'CP1c','CP6':'CP5c','P4':'P3c','P8':'P7c','PO4':'PO3c','O2':'O1c'}\n",
    "    \n",
    "chs_map_lParetic = {'Fp2':'Fp1i','AF4':'AF3i','F4':'F3i','F8':'F7i','FC2':'FC1i','FC6':'FC5i','C4':'C3i',\n",
    "                        'T8':'T7i','CP2':'CP1i','CP6':'CP5i','P4':'P3i','P8':'P7i','PO4':'PO3i','O2':'O1i',\n",
    "                       'Fp1':'Fp1c','AF3':'AF3c','F3':'F3c','F7':'F7c','FC1':'FC1c','FC5':'FC5c','C3':'C3c',\n",
    "                       'T7':'T7c','CP1':'CP1c','CP5':'CP5c','P3':'P3c','P7':'P7c','PO3':'PO3c','O1':'O1c'}\n",
    "\n",
    "bad_eeg_chs = {'2':\n",
    "               {'iMC':{'s01':['T8','C3','CP6'],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '3':\n",
    "               {'iMC':{'s01':[],'s02':[]},\n",
    "                'iVC':{'s01':['T8','T7'],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "                '4':\n",
    "               {'iMC':{'s01':['Pz','T8'],'s02':['T8']},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '6':\n",
    "               {'iMC':{'s01':[],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "                '10':\n",
    "               {'iMC':{'s01':['FC5c'],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '14':\n",
    "               {'iMC':{'s01':[],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '15':\n",
    "               {'iMC':{'s01':['T7c'],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '16':\n",
    "               {'iMC':{'s01':[],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '17':\n",
    "               {'iMC':{'s01':[],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '18':\n",
    "               {'iMC':{'s01':['F3c','Fp1c','AF3c'],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '19':\n",
    "               {'iMC':{'s01':['P7i', 'P7c'],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '20':\n",
    "               {'iMC':{'s01':[],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '21':\n",
    "               {'iMC':{'s01':['PO3c'],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '24':\n",
    "               {'iMC':{'s01':['FC5i','C3c'],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '25':\n",
    "               {'iMC':{'s01':['P7c'],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '30':\n",
    "               {'iMC':{'s01':['C3i', 'PO3i'],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '32':\n",
    "               {'iMC':{'s01':['F7i', 'T7c', 'Fz'],'s02':[]},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '34':\n",
    "               {'iMC':{'s01':['PO3i', 'O1i'],'s02':['PO3','CP6','P3']},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               },\n",
    "               '35':\n",
    "               {'iMC':{'s01':['PO3i'],'s02':['PO3']},\n",
    "                'iVC':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]}\n",
    "               }\n",
    "              }\n",
    "ICs2remove = {'2':\n",
    "               {'iMC':{'s01':[8],'s02':[]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "               },\n",
    "              '3':\n",
    "               {'iMC':{'s01':[],'s02':[]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "               },\n",
    "                '4':\n",
    "               {'iMC':{'s01':[0,2],'s02':[0]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "               },\n",
    "               '6':\n",
    "               {'iMC':{'s01':[],'s02':[]},\n",
    "                'iVC_push':{'s01':[0,5],'s02':[0,1,5],'s03':[0,3,12],'s04':[0,1,7],'s05':[0,1],'s06':[0,5]},\n",
    "                'iVC_pull':{'s01':[0],'s02':[0,1],'s03':[0],'s04':[0,1],'s05':[0],'s06':[0]},\n",
    "               },\n",
    "                '10':\n",
    "               {'iMC':{'s01':[0,2,3,7,15,17],'s02':[0,2,15,16,17]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[0],'s02':[0,4,7]}}\n",
    "               },\n",
    "              '14':\n",
    "               {'iMC':{'s01':[0,1,2,5,6,8,12,14],'s02':[]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[0,1,15],'s02':[]}}\n",
    "               },\n",
    "              '15':\n",
    "               {'iMC':{'s01':[0,1,2,3,7,11,15],'s02':[]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[0,1,2],'s02':[]}}\n",
    "               },\n",
    "              '16':\n",
    "               {'iMC':{'s01':[],'s02':[]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "               },\n",
    "              '17':\n",
    "               {'iMC':{'s01':[0],'s02':[]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[0,5],'s02':[]}}\n",
    "               },\n",
    "              '18':\n",
    "               {'iMC':{'s01':[0,1,3],'s02':[]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[0],'s02':[]}}\n",
    "               },\n",
    "              '19':\n",
    "               {'iMC':{'s01':[0,1,3],'s02':[]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[1],'s02':[]}}\n",
    "               },\n",
    "              '20':\n",
    "               {'iMC':{'s01':[0,1,3,4,5,7,8,9,10,11,12,13,14,15,16],'s02':[4,10]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[0,2],'s02':[]}}\n",
    "               },\n",
    "              '21':\n",
    "               {'iMC':{'s01':[2,3],'s02':[]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[3,7],'s02':[0,1,7,13]}}\n",
    "               },\n",
    "              '24':\n",
    "               {'iMC':{'s01':[0,1,3,9,15],'s02':[0,5]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[0,2],'s02':[0,1,2,3,4]}}\n",
    "               },      \n",
    "              '25':\n",
    "               {'iMC':{'s01':[0,1,5,7,10,12,13,15,17],'s02':[6]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[],'s02':[1]}}\n",
    "               },\n",
    "              '30':\n",
    "               {'iMC':{'s01':[0,1,3,4],'s02':[0,4]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[1,5],'s02':[6]}}\n",
    "               },\n",
    "              '32':\n",
    "               {'iMC':{'s01':[0,2,3,4,8,12],'s02':[1,7]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[0,2],'s02':[0,2]}}\n",
    "               },\n",
    "              '34':\n",
    "               {'iMC':{'s01':[0,1,2,5,6,8,10,11,14],'s02':[0,5,11,12]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[0,6],'s02':[0]}}\n",
    "               },\n",
    "              '35':\n",
    "               {'iMC':{'s01':[0,1,2,5,8,10,11,15],'s02':[0,1]},\n",
    "                'iVC_push':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'iVC_pull':{'s01':[],'s02':[],'s03':[],'s04':[],'s05':[],'s06':[]},\n",
    "                'srg':{'iMC':{'s01':[0,5],'s02':[0,3,4,6,9]}}\n",
    "               }              \n",
    "              }\n",
    "\n",
    "iMC_onsets_dict = {'10': {'iMC':{'s01':[29.8, 71, 109, 147, 184.3],}},\n",
    "                   '14':{'iMC':{'s01':[35,82,129.5,178,226],}},\n",
    "                   '15': {'iMC':{'s01':[27, 75.5, 125, 174, 224],}},\n",
    "                   '17': {'iMC':{'s01':[27.5, 76.5, 124.5, 174, 222.8],}},\n",
    "                   '18': {'iMC':{'s01':[26.5,76,125.5,175,224],}},\n",
    "                   '19': {'iMC':{'s01':[25,77,125,173,222],}},\n",
    "                   '20':{'iMC':{'s01':[41.5, 90.5, 140, 189]}},\n",
    "                   '21':{'iMC':{'s01':[37,87,136,185,234]}},\n",
    "                   '24':{'iMC':{'s01':[37,87,136,185,234]}},\n",
    "                   '25':{'iMC':{'s01':[32.5, 78, 125.5, 174.7, 223.7]}},\n",
    "                   '30':{'iMC':{'s01':[38.5, 89.5, 138, 188]}},\n",
    "                   '32':{'iMC':{'s01':[32.5,79.8,128,175.7,224.2]}},\n",
    "                   '34':{'iMC':{'s01':[29,79,128,177,226.5]}},\n",
    "                   '35':{'iMC':{'s01':[33.5,83,132.5,181,230]}}\n",
    "                  }\n",
    "\n",
    "chs_abnormal_linenoise_dict = {'10':{'iMC': {'s01':['O1i','O1c','F3c','Oz'],}},\n",
    "                               '14':{'iMC':{'s01':['T7i','F7i', 'FC5i'],}},\n",
    "                               '15':{'iMC': {'s01':['P3c', 'Pz'],}},\n",
    "                               '17':{'iMC':{'s01':[],}},\n",
    "                               '18':{'iMC':{'s01':['Cz', 'PO3c'],}},\n",
    "                               '19':{'iMC':{'s01':['P3i'],}},\n",
    "                               '20':{'iMC':{'s01':['FC5i', 'AF3i', 'F7i']}},\n",
    "                               '21':{'iMC':{'s01':[]}},\n",
    "                               '24':{'iMC':{'s01':['T7c', 'C3i', 'O1i']}},\n",
    "                               '25':{'iMC':{'s01':[]}},\n",
    "                               '30':{'iMC':{'s01':[]}},\n",
    "                               '32':{'iMC':{'s01':[]}},\n",
    "                               '34':{'iMC':{'s01':['Fp1i', 'F7i']}},\n",
    "                               '35':{'iMC':{'s01':['Fp1c']}},\n",
    "                      }\n",
    "\n",
    "epochs2remove = {'10': {'iMC':{'s01':[],}},\n",
    "                 '14':{'iMC':{'s01':[],}},\n",
    "                 '15': {'iMC':{'s01':[0],}},\n",
    "                 '17': {'iMC':{'s01':[],}},\n",
    "                 '18': {'iMC':{'s01':[],}},\n",
    "                 '19':{'iMC':{'s01':[2,3]}},\n",
    "                 '20':{'iMC':{'s01':[]}},\n",
    "                 '21':{'iMC':{'s01':[1,2,3]}},\n",
    "                 '24':{'iMC':{'s01':[1,2,4]}},\n",
    "                 '25':{'iMC':{'s01':[1,2]}},\n",
    "                 '30':{'iMC':{'s01':[]}},\n",
    "                 '32':{'iMC':{'s01':[4]}},\n",
    "                 '34':{'iMC':{'s01':[]}},\n",
    "                 '35':{'iMC':{'s01':[0,1]}},\n",
    "                  }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e6a9e-cfd0-4174-a113-a64c52f52bb1",
   "metadata": {},
   "source": [
    "## Filtering, identifying iMC onsets, chs with similar impedence, bad epochs\n",
    "in this step, we remove DC and identify possible artifacts (only remove ocular and muscular one). delete noisy epoch and identify the bad channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8eb4a1ef-ac20-4742-9e99-e0ad6e40ace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1', 'empty']\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 45 - 55 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 45.00\n",
      "- Lower transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Upper passband edge: 55.00 Hz\n",
      "- Upper transition bandwidth: 13.75 Hz (-6 dB cutoff frequency: 61.88 Hz)\n",
      "- Filter length: 147 samples (0.294 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Setting up band-pass filter from 10 - 2e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 10.00\n",
      "- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n",
      "- Upper passband edge: 200.00 Hz\n",
      "- Upper transition bandwidth: 50.00 Hz (-6 dB cutoff frequency: 225.00 Hz)\n",
      "- Filter length: 1321 samples (1.321 sec)\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=279998\n",
      "    Range : 0 ... 279997 =      0.000 ...   279.997 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/rjvcsg0s39b9750fsn4_8ylh0000gr/T/ipykernel_70453/4202559382.py:106: DeprecationWarning: highpass cannot be set directly. Please use methods inst.filter() instead. This warning will turn into an error after 0.24\n",
      "  raw_emg_2intergrate.info['highpass'] = raw_eeg_2intergrate.info['highpass']\n",
      "/var/folders/7q/rjvcsg0s39b9750fsn4_8ylh0000gr/T/ipykernel_70453/4202559382.py:107: DeprecationWarning: lowpass cannot be set directly. Please use method inst.filter() instead. This warning will turn into an error after 0.24\n",
      "  raw_emg_2intergrate.info['lowpass'] = raw_eeg_2intergrate.info['lowpass']\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "################## Customization ##################\n",
    "# data_dir = 'D:/Data/MultiEEGEMG_stroke/'\n",
    "data_dir = os.path.expanduser(\"/Users/ganshengt/Desktop/GT/gCMN/MultiEEGEMG_stroke\")\n",
    "subj_idx = '35'\n",
    "contraction_type = 'iMC'\n",
    "session_idx = 's01'\n",
    "sfreq_emg=1000\n",
    "sfreq_eeg=500\n",
    "# session_duration = 45  # default is 50s\n",
    "reject_criteria_eeg = dict(eeg=6e-4)       # 300 μV, do not exclude epochs containing ocular artifact\n",
    "flat_criteria_eeg = dict(eeg=1e-6)           # 1 μV\n",
    "manual_epoch = True\n",
    "n_epochs = 5\n",
    "\n",
    "################ fName\n",
    "emg_fName = os.path.join(data_dir,'subj'+subj_idx,'EMG','subj'+subj_idx+'_'+contraction_type+'_'+session_idx+'.txt')\n",
    "eeg_fName = os.path.join(data_dir,'subj'+subj_idx,'EEG','subj'+subj_idx+'_'+contraction_type+'_'+session_idx+'.set')\n",
    "ica_dir = os.path.join(data_dir,'subj'+subj_idx,'ica')\n",
    "epochs_f_ica_car_intpl_dir = os.path.join(data_dir,'subj'+subj_idx,'epochs_f_ica_car_intpl')\n",
    "prep_report_dir = os.path.join(data_dir,'subj'+subj_idx,'prep_report')\n",
    "if not os.path.exists(ica_dir):\n",
    "    os.makedirs(ica_dir)\n",
    "if not os.path.exists(epochs_f_ica_car_intpl_dir):\n",
    "    os.makedirs(epochs_f_ica_car_intpl_dir)\n",
    "if not os.path.exists(prep_report_dir):\n",
    "    os.makedirs(prep_report_dir)\n",
    "# ica_fName = os.path.join(data_dir,'subj'+subj_idx,'ica','subj'+subj_idx+'_'+contraction_type+'_'+session_idx+'_ica.fif')\n",
    "epochs_f_ica_car_intpl_fName = os.path.join(epochs_f_ica_car_intpl_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_f_ica_car_intpl_epo.fif')\n",
    "alignmentInfo_fName = os.path.join(data_dir,'subj'+subj_idx,'subj'+subj_idx+'_alignmentInfo.txt')\n",
    "alignmentInfo = pd.read_csv(alignmentInfo_fName, skiprows=0,sep = ',',engine = 'python')\n",
    "subjInfo_fName = os.path.join(data_dir,'subj_info.txt')\n",
    "subjInfo = pd.read_csv(subjInfo_fName, skiprows=0,\n",
    "                       sep = ',',engine = 'python') \n",
    "affected_h = subjInfo[subjInfo['subj_idx']==int(subj_idx)]['affected_h'].values[0]\n",
    "############################################################\n",
    "\n",
    "####### eeg reading ###########\n",
    "raw_eeg = mne.io.read_raw_eeglab(eeg_fName,preload=True)\n",
    "\n",
    "\n",
    "# electrode projection according to the affected hand\n",
    "if affected_h == 'l':\n",
    "    mne.channels.rename_channels(raw_eeg.info, chs_map_lParetic)\n",
    "elif affected_h == 'r':\n",
    "    mne.channels.rename_channels(raw_eeg.info, chs_map_rParetic)\n",
    "\n",
    "#     mne.rename_channels(raw_eeg.info, chs_map_rParetic)\n",
    "else:\n",
    "    print('check info file')\n",
    "\n",
    "    # ipsilesional always on the left brain\n",
    "enobio_montage = mne.channels.read_custom_montage(os.path.join(data_dir,'Enobio32_l_paretic.locs'))    \n",
    "raw_eeg.set_montage(enobio_montage)\n",
    "\n",
    "# alignment\n",
    "events,events_id = mne.events_from_annotations (raw_eeg)\n",
    "iMC_start = events[0][0] - alignmentInfo.loc[(alignmentInfo['sessionIdx']==session_idx) & \n",
    "                                      (alignmentInfo['contraction_type']==contraction_type),\n",
    "                                      'EEG'].values[0]  #data point\n",
    "raw_eeg.info['bads']=bad_eeg_chs[subj_idx][contraction_type][session_idx]\n",
    "\n",
    "raw_eeg.crop(tmin = alignmentInfo.loc[(alignmentInfo['sessionIdx']==session_idx) & \n",
    "                                      (alignmentInfo['contraction_type']==contraction_type),\n",
    "                                      'EEG'].values[0]/raw_eeg.info['sfreq'])\n",
    "\n",
    "# find chs with similar impedence\n",
    "raw_eeg_copy = raw_eeg.copy()\n",
    "raw_eeg_copy.filter(l_freq=45,h_freq=55)\n",
    "chs_noise_level = np.trapz(np.abs(raw_eeg_copy.get_data()), axis=1)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "df_chs_noise_level = pd.DataFrame(np.expand_dims(chs_noise_level, 0), columns=raw_eeg_copy.info['ch_names'])\n",
    "\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = sns.barplot(data=df_chs_noise_level)\n",
    "plt.axhline(y=df_chs_noise_level.mean().mean(), color='r', linestyle='-')\n",
    "plt.axhline(y=df_chs_noise_level.mean().mean()+ 2*df_chs_noise_level.mean().std(), color='b', linestyle='-')\n",
    "plt.axhline(y=df_chs_noise_level.mean().mean()- 2*df_chs_noise_level.mean().std(), color='b', linestyle='-')\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_line_noise_level.eps'))\n",
    "\n",
    "# filter\n",
    "raw_eeg.filter(l_freq=0.5,h_freq=45, method='iir')\n",
    "raw_eeg.notch_filter(freqs=np.arange(50, 201, 50))\n",
    "\n",
    "############# emg reading ##############\n",
    "ch_types = ['emg']*8\n",
    "ch_names = ['FDS', 'FCU', 'FCR', 'ECU', 'ECRL', 'BBS', 'TBL', 'LD']\n",
    "emg_data = pd.read_csv(emg_fName, header = None,skiprows=3, \n",
    "                       sep = ' ',usecols=np.arange(0,8),skipfooter=0,engine = 'python')\n",
    "############### alignment \n",
    "emg_data= emg_data.iloc[alignmentInfo.loc[(alignmentInfo['sessionIdx']==session_idx) & \n",
    "                                      (alignmentInfo['contraction_type']==contraction_type),\n",
    "                                      'EMG'].values[0]:,:].values\n",
    "############## band-pass filter\n",
    "emg_data=emg_data.T/1e6\n",
    "emg_data = mne.filter.filter_data(emg_data,sfreq=1000,l_freq=10,h_freq=200)\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq_emg, ch_types=ch_types)\n",
    "raw_emg = mne.io.RawArray(emg_data, info)\n",
    "\n",
    "# integration\n",
    "raw_eeg_2intergrate = raw_eeg.copy()\n",
    "raw_emg_2intergrate = raw_emg.copy()\n",
    "raw_emg_2intergrate.resample(sfreq=sfreq_eeg)\n",
    "hybrid_tmax = min(raw_eeg.get_data().shape[1],raw_emg_2intergrate.get_data().shape[1]) / sfreq_eeg - 1\n",
    "raw_emg_2intergrate.crop(tmax =hybrid_tmax)\n",
    "raw_eeg_2intergrate.crop(tmax =hybrid_tmax)\n",
    "raw_emg_2intergrate.info['highpass'] = raw_eeg_2intergrate.info['highpass']\n",
    "raw_emg_2intergrate.info['lowpass'] = raw_eeg_2intergrate.info['lowpass']\n",
    "# events, events_id = mne.events_from_annotations(raw_eeg)\n",
    "raw_hybrid = raw_eeg_2intergrate.add_channels([raw_emg_2intergrate])\n",
    "fig = raw_eeg.plot(title='raw_eeg', n_channels=16, duration=40, scalings=dict(eeg=5e-5))\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_raw_eeg.eps'))\n",
    "\n",
    "# epoch\n",
    "\n",
    "# iMC_onsets = np.linspace(start = events[0][0]/raw_eeg.info['sfreq'], \n",
    "#                          stop = events[0][0]/raw_eeg.info['sfreq']+ session_duration*4, num=5) - raw_eeg.first_time\n",
    "# manual edition\n",
    "if manual_epoch:\n",
    "    iMC_onsets = iMC_onsets_dict[subj_idx][contraction_type][session_idx]\n",
    "else:\n",
    "    foundOnsets, iMC_onsets = findOnsets(5,raw_emg,['FCR'],step=1000, windowLen=3000, energy_q_step=0.03, sfreq_emg=1000)\n",
    "    if foundOnsets:\n",
    "        print(iMC_onsets)\n",
    "    else:\n",
    "        print('fail in identifying onsets')\n",
    "\n",
    "durations = [0.] * n_epochs\n",
    "descriptions = ['onset_iMC'] * n_epochs\n",
    "annot = mne.Annotations(onset=iMC_onsets, duration=durations,\n",
    "                                    description=descriptions,\n",
    "                                    orig_time=raw_eeg.info['meas_date'])\n",
    "\n",
    "raw_hybrid.set_annotations(annot)\n",
    "fig = raw_hybrid.plot(title='raw_hybrid', start=50, n_channels=40, duration=40, scalings=dict(eeg=4e-5, emg=5e-4))\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_raw_hybrid.eps'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e18c8b0-7ae1-451d-a512-5757f5c7097e",
   "metadata": {},
   "source": [
    "## epoch data and ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cc6486e2-2428-4b86-b837-b16e0ad7db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['onset_iMC']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "5 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 5 events and 15001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Dropped 2 epochs: 0, 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n",
      "Selecting by explained variance: 16 components\n",
      "Fitting ICA took 0.4s.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "events,events_id = mne.events_from_annotations (raw_hybrid)\n",
    "epochs_hybrid = mne.Epochs(raw_hybrid,events,tmin=-15.0,tmax=15.0,baseline=None,preload=True)\n",
    "\n",
    "# remove noisy epochs\n",
    "epochs_hybrid.drop(epochs2remove[subj_idx][contraction_type][session_idx])\n",
    "fig = epochs_hybrid.plot(n_epochs=1, title='epochs_hybrid')\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_epoch_hybrid.eps'))\n",
    "\n",
    "# ICA\n",
    "ica = ICA(n_components = 0.99,random_state=97)\n",
    "ica.fit(epochs_hybrid)\n",
    "fig = ica.plot_sources(epochs_hybrid,stop=1)\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_ica_source.eps'))\n",
    "fig = ica.plot_components(inst = epochs_hybrid)\n",
    "fig[0].savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_ica_comp_.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38181980-dfe4-4563-b11d-3fe4471e2584",
   "metadata": {},
   "source": [
    "## Remove artifactual ICs\n",
    "- remove EOG, ECG, EMG, and fluctuation with great amplitude, NOTE that widespread EMG, ECG can be removed with CAR\n",
    "- use bad ch and remove epoch to remove ch-localized/temporal localized artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ef911877-66b7-4bfe-9f70-5d3b6f4f9f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (16 components)\n",
      "    Zeroing out 8 ICA components\n",
      "    Projecting back using 31 PCA components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "# remove ICs\n",
    "ica.exclude = ICs2remove[subj_idx][contraction_type][session_idx]\n",
    "for ic in ica.exclude:\n",
    "    fig = ica.plot_properties(inst = epochs_hybrid, picks=ic) \n",
    "    fig[0].savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_ica_component_' + str(ic) + '.jpg'))\n",
    "epochs_hybrid_ica = epochs_hybrid.copy()\n",
    "ica.apply(epochs_hybrid_ica)\n",
    "fig = epochs_hybrid_ica.plot(n_epochs=1,title='after ica')\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_epochs_afterICA.eps'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ae23ee-a976-4907-8124-c2ebfd155579",
   "metadata": {},
   "source": [
    "## Common average reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "95298cef-02c4-44ec-ab59-6cf724d5e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "epochs_hybrid_ica_car = epochs_hybrid_ica.copy()\n",
    "for ch in chs_abnormal_linenoise_dict[subj_idx][contraction_type][session_idx]:\n",
    "    if ch not in epochs_hybrid_ica_car.info['bads']:\n",
    "        epochs_hybrid_ica_car.info['bads'].append(ch)\n",
    "epochs_hybrid_ica_car, ref_data = mne.set_eeg_reference(epochs_hybrid_ica_car, ref_channels=list(np.setdiff1d(epochs_hybrid_ica_car.info['ch_names'][:32],\n",
    "                                                                                                  epochs_hybrid_ica_car.info['bads'])))\n",
    "fig = epochs_hybrid_ica_car.plot(title='car', n_epochs=1)\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_epochs_afterCAR.eps'))\n",
    "# mne.set_eeg_reference(epochs_hybrid_prep, ref_channels=['AF3', 'AF4', 'C3', 'C4', 'CP1', 'CP2', 'CP5', 'CP6', 'Cz', 'F3', 'F4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab1475-9377-41ce-9863-b5abf3b0fb8e",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2ae27050-099b-45fa-88a2-6291fa4e911c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating bad channels\n",
      "    Automatic origin fit: head of radius 95.0 mm\n",
      "Computing interpolation matrix from 30 sensor positions\n",
      "Interpolating 2 sensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "epochs_hybrid_ica_car_intpl = epochs_hybrid_ica_car.interpolate_bads()\n",
    "fig = epochs_hybrid_ica_car_intpl.plot(n_epochs=1, title='interpolated')\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_epochs_afterITPL.eps'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a88e1c-c12e-4d72-8097-81abbd1b748b",
   "metadata": {},
   "source": [
    "## PSD for specified ch and all chs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1ead328c-206e-4d00-aa7f-8dfd40034c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.024 (s)\n",
      "Effective window size : 1.024 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using multitaper spectrum estimation with 7 DPSS windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using multitaper spectrum estimation with 7 DPSS windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "ch_name = 'C3i'\n",
    "epo_idx = 1\n",
    "kwargs = dict(fmin=1, fmax=40, n_jobs=1)\n",
    "psds_welch_mean_baseline, freqs_mean_baseline = psd_welch(epochs_hybrid_ica_car_intpl.copy().crop(tmin=-10,tmax=-1), average='mean', n_fft=512, **kwargs)\n",
    "psds_welch_mean_motor, freqs_mean_motor = psd_welch(epochs_hybrid_ica_car_intpl.copy().crop(tmin=0,tmax=9), average='mean', n_fft=512, **kwargs)\n",
    "\n",
    "# Convert power to dB scale.\n",
    "psds_welch_mean_baseline = 10 * np.log10(psds_welch_mean_baseline * 1e12)\n",
    "psds_welch_mean_motor = 10 * np.log10(psds_welch_mean_motor * 1e12)\n",
    "\n",
    "ch_idx = epochs_hybrid_ica_car_intpl.info['ch_names'].index(ch_name)\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(freqs_mean_baseline, psds_welch_mean_baseline[epo_idx, ch_idx, :], color='k',\n",
    "        ls='--', label='baseline')\n",
    "ax.plot(freqs_mean_motor, psds_welch_mean_motor[epo_idx, ch_idx, :], color='k',\n",
    "        ls='-', label='motor')\n",
    "ax.set(title='Welch PSD ({}, Epoch {})'.format(ch_name, epo_idx),\n",
    "       xlabel='Frequency (Hz)', ylabel='Power Spectral Density (dB, V^2/Hz)')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()\n",
    "fig=ax.get_figure()\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_' + str(ch_name) + '_epoch' + str(epo_idx) + '_welch_psd.eps'))\n",
    "\n",
    "# across trials\n",
    "psds_welch_mean_baseline_across_trials = np.mean(psds_welch_mean_baseline, axis=0)\n",
    "psds_welch_mean_motor_across_trials = np.mean(psds_welch_mean_motor, axis=0)\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(freqs_mean_baseline, psds_welch_mean_baseline_across_trials[ch_idx, :], color='k',\n",
    "        ls='--', label='baseline')\n",
    "ax.plot(freqs_mean_motor, psds_welch_mean_motor_across_trials[ch_idx, :], color='k',\n",
    "        ls='-', label='motor')\n",
    "\n",
    "ax.set(title='Welch PSD ({})'.format(ch_name),\n",
    "       xlabel='Frequency (Hz)', ylabel='Power Spectral Density (dB)')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()\n",
    "fig=ax.get_figure()\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_' + str(ch_name) + '_all_epochs_welch_psd.eps'))\n",
    "\n",
    "fig = epochs_hybrid_ica_car_intpl.plot_psd(fmin=1., fmax=40., tmin=-10, tmax=-1, average=True, normalization='full')\n",
    "fig.legend(['all chs, baseline'])\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_all_chs_baseline_multitaper_psd.eps'))\n",
    "\n",
    "fig = epochs_hybrid_ica_car_intpl.plot_psd(fmin=1., fmax=40., tmin=0, tmax=10, average=True, normalization='full')\n",
    "fig.legend(['all chs, motor'])\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_all_chs_motor_multitaper_psd.eps'))\n",
    "# epochs_hybrid_prep_car_intpl.plot_psd_topomap(ch_type='eeg', normalize=False)\n",
    "# power.plot_topo(baseline=(-0.5, 0), mode='logratio', title='Average power')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326cb738-3d28-4316-b26e-2f484841c042",
   "metadata": {},
   "source": [
    "## topograph of bands (morlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6244745a-4161-4d45-8a1b-217badd2cdf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs_hybrid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7q/rjvcsg0s39b9750fsn4_8ylh0000gr/T/ipykernel_18675/1811307599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_cycles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;31m# different number of cycle per frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m power, itc = tfr_morlet(epochs_hybrid.copy().crop(tmin=-6,tmax=4), freqs=freqs, n_cycles=n_cycles, use_fft=True,\n\u001b[0m\u001b[1;32m      6\u001b[0m                         return_itc=True, decim=3, n_jobs=1)\n\u001b[1;32m      7\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_topo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logratio'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Average power'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs_hybrid' is not defined"
     ]
    }
   ],
   "source": [
    "freqs = np.logspace(*np.log10([4, 30]), num=20)\n",
    "baseline = (-6, -1)\n",
    "n_cycles = freqs/2 # different number of cycle per frequency\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "power, itc = tfr_morlet(epochs_hybrid.copy().crop(tmin=-6,tmax=4), freqs=freqs, n_cycles=n_cycles, use_fft=True,\n",
    "                        return_itc=True, decim=3, n_jobs=1)\n",
    "power.plot_topo(baseline=baseline, mode='logratio', title='Average power')\n",
    "\n",
    "fig, axis = plt.subplots(1, 3, figsize=(12, 5))\n",
    "# power.plot_topomap(ch_type='eeg', tmin=0, tmax=10, fmin=1, fmax=4,\n",
    "#                    baseline=baseline, mode='logratio', axes=axis[0][0],\n",
    "#                    title='Delta', show=False)\n",
    "power.plot_topomap(ch_type='eeg', tmin=-1, tmax=4, fmin=4, fmax=8, \n",
    "                   baseline=baseline, mode='logratio', axes=axis[0],\n",
    "                   title='Theta (motor-baseline)', show=False)\n",
    "power.plot_topomap(ch_type='eeg', tmin=-1, tmax=4, fmin=8, fmax=12,\n",
    "                   baseline=baseline, mode='logratio', axes=axis[1],\n",
    "                   title='Alpha (motor-baseline)', show=False)\n",
    "power.plot_topomap(ch_type='eeg', tmin=-1, tmax=4, fmin=13, fmax=30,\n",
    "                   baseline=baseline, mode='logratio', axes=axis[2],\n",
    "                   title='Beta (motor-baseline)', show=False)\n",
    "# fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + '_tf_band_topo.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6fd562-f843-4d53-8990-cb843b74efba",
   "metadata": {},
   "source": [
    "## Save epochs for further analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7d504fb9-b8a7-408e-9340-463e9f8a1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_hybrid_ica_car_intpl.save(epochs_f_ica_car_intpl_fName,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e10ca1-79f2-4bba-b4fb-852921a3eeb7",
   "metadata": {},
   "source": [
    "## Oscillation analysis\n",
    "\n",
    "### Information to keep\n",
    "- power spectrum for each electrode, each trial (welch psd)\n",
    "- fitting features including center frequency, power, bandwidth of peaks, offset, knee and exponent of the aperiodic component\n",
    "\n",
    "### data format would be\n",
    "\n",
    "| subj | task | session |  ch |   epoch   |   trial   | freq_range |  spectrum  | center_freq | power | bandwidth | offset |  exponent | R2 | error |\n",
    "| ---- | ---- | ------- | --- | --------- | --------- | ---------- | ---------- | ----------- | ----- | --------- | ------ |  -------- | -- | ----- |\n",
    "|.  20 | imc  | pre_TMS | C3i |  averaged | motor.    |  \\[list\\]  |  \\[list\\]  |   \\[list\\]  | list. | list.     |  list  |   lits.   |    |.      |\n",
    "\n",
    "### Knee is not considered in the fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "09b54625-45c6-4abe-baa4-e8c29f2a2e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.024 (s)\n",
      "Effective window size : 1.024 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganshengt/opt/anaconda3/envs/p38/lib/python3.8/site-packages/fooof/objs/group.py:378: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  out = np.array([np.insert(getattr(data, name), 3, index, axis=1)\n",
      "/Users/ganshengt/opt/anaconda3/envs/p38/lib/python3.8/site-packages/fooof/objs/group.py:378: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  out = np.array([np.insert(getattr(data, name), 3, index, axis=1)\n",
      "/var/folders/7q/rjvcsg0s39b9750fsn4_8ylh0000gr/T/ipykernel_70453/1810489079.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(ncols=3, figsize=(12, 4), gridspec_kw=dict(top=0.9),\n"
     ]
    }
   ],
   "source": [
    "fg = FOOOFGroup(peak_width_limits=[1, 6], min_peak_height=0.15, peak_threshold=2, max_n_peaks=4, verbose=False, aperiodic_mode='fixed')\n",
    "freq_range = [2,40]\n",
    "kwargs = dict(fmin=1, fmax=40, n_jobs=1)\n",
    "\n",
    "dict_2df = {'subj':[],\n",
    "           'task':[],\n",
    "           'session':[],\n",
    "           'ch':[],\n",
    "           'trial':[],\n",
    "           'freq_range':[],\n",
    "           'spectrum':[],\n",
    "           'center_freq':[],\n",
    "           'power':[],\n",
    "           'bandwidth':[],\n",
    "           'offset':[],\n",
    "           'exponent':[],\n",
    "           'R2':[],\n",
    "           'error':[]}\n",
    "\n",
    "bands = Bands({'theta': [3, 7],\n",
    "               'alpha': [8, 12],\n",
    "               'beta': [13, 30]})\n",
    "ax_x_start = 0.95\n",
    "ax_x_width = 0.02\n",
    "ax_y_start = 0.1\n",
    "ax_y_height = 0.7\n",
    "# for ch in epochs_hybrid_ica_car_intpl.info['ch_names'][:32]:\n",
    "psds_welch_baseline, freqs_baseline = psd_welch(epochs_hybrid_ica_car_intpl.copy().crop(tmin=-11,tmax=-1), average='mean', n_fft=512, **kwargs)\n",
    "psds_welch_motor, freqs_motor = psd_welch(epochs_hybrid_ica_car_intpl.copy().crop(tmin=-1,tmax=9), average='mean', n_fft=512, **kwargs)\n",
    "# psd: epoch * ch * spect\n",
    "psds_welch_baseline_averaged_over_trials = np.mean(psds_welch_baseline * 1e12, axis=0)  # change unit to V2/Hz  \n",
    "psds_welch_motor_averaged_over_trials = np.mean(psds_welch_motor * 1e12, axis=0)\n",
    "for trial in ['baseline', 'motor']:\n",
    "    exec('fg.fit(freqs_' + trial + ', psds_welch_' + trial + '_averaged_over_trials, freq_range)')\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(12, 4), gridspec_kw=dict(top=0.9),\n",
    "                           sharex=True, sharey=True)\n",
    "\n",
    "    thetas = get_band_peak_fg(fg, bands.theta)\n",
    "    alphas = get_band_peak_fg(fg, bands.alpha)\n",
    "    betas = get_band_peak_fg(fg, bands.beta)\n",
    "\n",
    "    # Extract the power values from the detected peaks\n",
    "    exec('theta_pw_' + trial + '= np.nan_to_num(thetas[:, 1])')\n",
    "    exec('alpha_pw_' + trial + '= np.nan_to_num(alphas[:, 1])')\n",
    "    exec('beta_pw_' + trial + '= np.nan_to_num(betas[:, 1])')\n",
    "    exec('plot_topomap(theta_pw_' + trial + ', raw_eeg.info, axes=ax[0], show=False)')\n",
    "    exec('plot_topomap(alpha_pw_' + trial + ', raw_eeg.info, axes=ax[1], show=False)')\n",
    "    exec('im, cm = plot_topomap(beta_pw_' + trial + ', raw_eeg.info, axes=ax[2], show=False)')\n",
    "    ax[0].set_title('Theta', fontweight='bold')\n",
    "    ax[1].set_title('Alpha', fontweight='bold')\n",
    "    ax[2].set_title('Beta', fontweight='bold')\n",
    "\n",
    "    cbar_ax = fig.add_axes([ax_x_start, ax_y_start, ax_x_width, ax_y_height])\n",
    "    clb = fig.colorbar(im, cax=cbar_ax)\n",
    "    clb.ax.set_title('peak power',fontsize=20)\n",
    "    fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + trial + '_pw_topo.jpg'))\n",
    "    # build feature df\n",
    "    for ch_result_idx in range(len(fg.group_results)):\n",
    "        n_peaks = fg.group_results[ch_result_idx].peak_params.shape[0]\n",
    "        for peak_idx in range(n_peaks):\n",
    "            dict_2df['ch'].append(epochs_hybrid_ica_car_intpl.info['ch_names'][ch_result_idx])\n",
    "            dict_2df['trial'].append(trial)\n",
    "            dict_2df['spectrum'].append(fg.power_spectra[ch_result_idx])\n",
    "            dict_2df['center_freq'].append(fg.group_results[ch_result_idx].peak_params[peak_idx][0])\n",
    "            dict_2df['power'].append(fg.group_results[ch_result_idx].peak_params[peak_idx][1])\n",
    "            dict_2df['bandwidth'].append(fg.group_results[ch_result_idx].peak_params[peak_idx][2])\n",
    "            dict_2df['offset'].append(fg.group_results[ch_result_idx].aperiodic_params[0])\n",
    "            dict_2df['exponent'].append(fg.group_results[ch_result_idx].aperiodic_params[1])\n",
    "            dict_2df['R2'].append(fg.group_results[ch_result_idx].r_squared)\n",
    "            dict_2df['error'].append(fg.group_results[ch_result_idx].error)\n",
    "\n",
    "dict_2df['subj'] = [str(subj_idx)] * len(dict_2df['ch'])\n",
    "dict_2df['task'] = ['imc'] * len(dict_2df['ch'])\n",
    "dict_2df['session'] = ['pre_TMS'] * len(dict_2df['ch'])\n",
    "dict_2df['freq_range'] = [freqs_baseline] * len(dict_2df['ch'])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(12, 4), gridspec_kw=dict(top=0.9),\n",
    "                       sharex=True, sharey=True)\n",
    "plot_topomap(theta_pw_motor - theta_pw_baseline, raw_eeg.info, axes=ax[0], show=False)\n",
    "plot_topomap(alpha_pw_motor - alpha_pw_baseline, raw_eeg.info, axes=ax[1], show=False)\n",
    "im, cm = plot_topomap(beta_pw_motor - beta_pw_baseline, raw_eeg.info, axes=ax[2], show=False)\n",
    "\n",
    "ax[0].set_title('Theta', fontweight='bold')\n",
    "ax[1].set_title('Alpha', fontweight='bold')\n",
    "ax[2].set_title('Beta', fontweight='bold')\n",
    "cbar_ax = fig.add_axes([ax_x_start, ax_y_start, ax_x_width, ax_y_height])\n",
    "clb = fig.colorbar(im, cax=cbar_ax)\n",
    "clb.ax.set_title('peak power (motor-baseline)',fontsize=20)\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + 'motor_baseline_pw_topo.jpg'))\n",
    "fig.savefig(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + 'motor_baseline_pw_topo.eps'))\n",
    "\n",
    "df = pd.DataFrame(dict_2df)\n",
    "df.to_csv(os.path.join(prep_report_dir, 'subj' + subj_idx + '_' + contraction_type + '_' + session_idx + 'psd_fit.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ffc2387d-670e-4833-9afb-b5a062195ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      "                                                                                                  \n",
      "                                       FOOOF - GROUP RESULTS                                      \n",
      "                                                                                                  \n",
      "                             Number of power spectra in the Group: 32                             \n",
      "                                                                                                  \n",
      "                        The model was run on the frequency range 2 - 40 Hz                        \n",
      "                                 Frequency Resolution is 0.98 Hz                                  \n",
      "                                                                                                  \n",
      "                              Power spectra were fit without a knee.                              \n",
      "                                                                                                  \n",
      "                                      Aperiodic Fit Values:                                       \n",
      "                        Exponents - Min: -0.358, Max:  1.254, Mean: 0.458                         \n",
      "                                                                                                  \n",
      "                         In total 104 peaks were extracted from the group                         \n",
      "                                                                                                  \n",
      "                                     Goodness of fit metrics:                                     \n",
      "                            R2s -  Min:  0.518, Max:  0.988, Mean: 0.860                          \n",
      "                         Errors -  Min:  0.033, Max:  0.092, Mean: 0.054                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganshengt/opt/anaconda3/envs/p38/lib/python3.8/site-packages/fooof/objs/group.py:378: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  out = np.array([np.insert(getattr(data, name), 3, index, axis=1)\n"
     ]
    }
   ],
   "source": [
    "fg.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9e847-34fc-4094-91ec-16171389864f",
   "metadata": {},
   "source": [
    "## Chapter 2: synergy calculation\n",
    "### Section 2-1: import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650c34f-085a-4271-88ff-2ecac9cbb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_hybrid_ica_car_intpl = mne.read_epochs(epochs_f_ica_car_intpl_fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174127ba-b45e-48a5-9935-65e173ee13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The length of baseline segment is 18s, we generate 30 3s epochs with a step of 0.5s\n",
    "'''\n",
    "srg_tmin = 0.0\n",
    "srg_tmax = 18.001\n",
    "length_epochs = 3\n",
    "n_srg_epochs = 15\n",
    "sliding_step = 1\n",
    "length_rect_epochs = 16\n",
    "n_srg_rect_epochs = 10\n",
    "sliding_step_rect = 0.2\n",
    "\n",
    "# create epochs_srg #\n",
    "motorPeriods = ['', '_rect']\n",
    "for motorPeriod in motorPeriods:\n",
    "    srg_raw = aligned_raw.copy().crop(tmin=srg_tmin, tmax=srg_tmax)\n",
    "    exec('srg' + motorPeriod + '_onsets = np.arange(0, n_srg' + motorPeriod + '_epochs * sliding_step' + motorPeriod + ', sliding_step' + motorPeriod + ')')\n",
    "    exec('durations = [0.] * len(' + 'srg' + motorPeriod + '_onsets)')\n",
    "    descriptions = ['srgOnset'] * len(durations)\n",
    "    exec('annot_srg = mne.Annotations(onset=srg' + motorPeriod + '_onsets, duration=durations,\\\n",
    "                            description=descriptions, orig_time=aligned_raw.info[\"meas_date\"])')\n",
    "    srg_raw.set_annotations(annot_srg)\n",
    "    events, events_id = mne.events_from_annotations(srg_raw)\n",
    "    # No rejection occurred\n",
    "    exec('srg' + motorPeriod + '_epochs = mne.Epochs(srg_raw, events, tmin=0.0, tmax=length' + motorPeriod + '_epochs, baseline=None, preload=True)')\n",
    "    exec('srg' + motorPeriod + '_epochs.save(srg' + motorPeriod + '_epochs_fName, overwrite=True)')\n",
    "    \n",
    "    # calculate muscle synergy epochs\n",
    "    exec('srg_onsets_samplePoints = sfreq_emg * srg' + motorPeriod + '_onsets')\n",
    "    exec('synergy_factor' + motorPeriod + '_epochs_data = []')\n",
    "    n_components = 4\n",
    "    muscle_synergy_data = []\n",
    "    VAF2df = []\n",
    "    VAF_diff2df = []\n",
    "    for onset in srg_onsets_samplePoints:\n",
    "        # 3002 -> 1501 for 3s\n",
    "        exec('muscle_synergy, synergy_factor, VAF, VAF_diff = emg2synergy(emg_data[:, int(onset):int(onset+length' + motorPeriod +\n",
    "             '_epochs * sfreq_emg + 2)], emg_ch_names=emg_ch_names, show=False, n_components=n_components)')  # 2get the same length\n",
    "        exec('synergy_factor' + motorPeriod + '_epochs_data.append(synergy_factor)')\n",
    "        muscle_synergy_data.append(muscle_synergy)\n",
    "        VAF2df.append(VAF)\n",
    "        VAF_diff2df.append(VAF_diff)\n",
    "        \n",
    "    muscle_synergy_data2df = np.zeros((len(srg_onsets_samplePoints) * n_components, len(emg_ch_names) + 2))\n",
    "    for n_synergy in range(n_components):\n",
    "        for n_epoch in range(len(srg_onsets_samplePoints)):\n",
    "            muscle_synergy_data2df[(n_epoch) * n_components + n_synergy, :] = np.hstack([muscle_synergy_data[n_epoch].T[n_synergy],\n",
    "                                                                                        [n_synergy + 1, n_epoch]])\n",
    "    df_muscle_synergy = pd.DataFrame(data=muscle_synergy_data2df, columns=emg_ch_names + ['n_synergy', 'n_epoch'])\n",
    "    exec('df_muscle_synergy.to_csv(df_srg' + motorPeriod + '_muscle_synergy_fName)')\n",
    "         \n",
    "    VAF_data2df = np.zeros((len(VAF2df), 2 * np.shape(VAF2df)[1] + 1))\n",
    "    for n_compoent in range(np.shape(VAF2df)[1]):   # range of n_components based on which NMF was fitted\n",
    "        for n_epoch in range(np.shape(VAF2df)[0]):  # number of epochs\n",
    "            VAF_data2df[n_epoch, :] = np.hstack([VAF2df[n_epoch], VAF_diff2df[n_epoch], [n_epoch]])\n",
    "    df_VAF = pd.DataFrame(data=VAF_data2df, columns=['VAF_'+str(i+2) for i in range(np.shape(VAF2df)[1])] +\n",
    "                          ['VAF_diff_'+str(i+2) for i in range(np.shape(VAF2df)[1])] + ['n_epoch'])  # n starts from 2\n",
    "    exec('df_VAF.to_csv(df_srg' + motorPeriod + '_VAF_fName)')\n",
    "    \n",
    "    # visual inspect noisy epochs (extreme participant movements)\n",
    "    # create synergy epochs\n",
    "    exec('ch_types = [\"emg\"] * np.shape(synergy_factor' + motorPeriod + '_epochs_data)[1]')  # number of synergies\n",
    "    exec('synergy_ch_names = [\"synergy_\" + str(i+1) for i in range(np.shape(synergy_factor' + motorPeriod +'_epochs_data)[1])]')\n",
    "    info = mne.create_info(ch_names=synergy_ch_names, sfreq=sfreq_emg, ch_types=ch_types)\n",
    "    exec('srg' + motorPeriod + '_synergy_epochs = srg' + motorPeriod + '_epochs.copy()')\n",
    "    exec('srg' + motorPeriod + '_synergy_epochs.drop_channels(emg_ch_names)')\n",
    "    exec('synergy_epochs = mne.EpochsArray(synergy_factor' + motorPeriod + '_epochs_data, info=info).resample(sfreq=sfreq_eeg)')\n",
    "    exec('synergy_epochs.info[\"highpass\"] = srg' + motorPeriod + '_synergy_epochs.info[\"highpass\"]')\n",
    "    exec('synergy_epochs.info[\"lowpass\"] = srg' + motorPeriod + '_synergy_epochs.info[\"lowpass\"]')\n",
    "    exec('srg' + motorPeriod + '_synergy_epochs.add_channels([synergy_epochs])')  # eeg-synergy epochs \n",
    "    exec('srg' + motorPeriod + '_synergy_epochs.save(srg' + motorPeriod + '_synergy_epochs_fName, overwrite=True)')\n",
    "    exec('srg' + motorPeriod + '_synergy_epochs.plot(scalings=dict(eeg=1e-4, emg=srg' + motorPeriod +\n",
    "         '_synergy_epochs.get_data().max()/2), picks=\"all\", title=\"srg' + motorPeriod + '_synergy_epochs\")')  # all epochs are plotted at once\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p38] *",
   "language": "python",
   "name": "conda-env-p38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
